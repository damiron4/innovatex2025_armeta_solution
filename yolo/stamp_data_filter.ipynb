{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690b0819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Stamp Dataset - Keep Only First 3 Classes\n",
    "\n",
    "This notebook filters the stamp_yolov9 dataset to keep only classes 0, 1, 2 (circle, oval, rectangle) and removes classes 3, 4 (triangle, word)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef64750e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Distribution in Filtered Dataset:\n",
      "==================================================\n",
      "\n",
      "TRAIN:\n",
      "  Class 1 (stamp): 3136 annotations\n",
      "  Total annotations: 3136\n",
      "\n",
      "VALID:\n",
      "  Class 1 (stamp): 318 annotations\n",
      "  Total annotations: 318\n",
      "\n",
      "TEST:\n",
      "  Class 1 (stamp): 154 annotations\n",
      "  Total annotations: 154\n"
     ]
    }
   ],
   "source": [
    "# Verify class distribution in filtered dataset\n",
    "from collections import Counter\n",
    "\n",
    "def count_classes(split):\n",
    "    labels_dir = Path(OUTPUT_DIR) / split / \"labels\"\n",
    "    if not labels_dir.exists():\n",
    "        return Counter()\n",
    "    \n",
    "    class_counts = Counter()\n",
    "    for label_file in labels_dir.glob(\"*.txt\"):\n",
    "        with open(label_file, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 5:\n",
    "                    class_id = int(parts[0])\n",
    "                    class_counts[class_id] += 1\n",
    "    return class_counts\n",
    "\n",
    "print(\"\\nClass Distribution in Filtered Dataset:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "class_names = {1: 'stamp'}\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    counts = count_classes(split)\n",
    "    if counts:\n",
    "        print(f\"\\n{split.upper()}:\")\n",
    "        for class_id in sorted(counts.keys()):\n",
    "            class_name = class_names.get(class_id, f\"unknown({class_id})\")\n",
    "            print(f\"  Class {class_id} ({class_name}): {counts[class_id]} annotations\")\n",
    "        print(f\"  Total annotations: {sum(counts.values())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96c7fc6",
   "metadata": {},
   "source": [
    "## Verify Results (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f710fc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ data.yaml created\n",
      "\n",
      "Filtered dataset ready at: ../datasets/stamp_yolov9_filtered\n",
      "All stamp shapes (circle, oval, rectangle) remapped to class ID 1\n"
     ]
    }
   ],
   "source": [
    "# Create updated data.yaml with single stamp class\n",
    "yaml_content = \"\"\"train: ../train/images\n",
    "val: ../valid/images\n",
    "test: ../test/images\n",
    "\n",
    "nc: 1\n",
    "names: ['stamp']\n",
    "\n",
    "roboflow:\n",
    "  workspace: swp-3jks1\n",
    "  project: stamp-shape-filtered\n",
    "  version: 3\n",
    "  license: Public Domain\n",
    "  url: https://universe.roboflow.com/swp-3jks1/stamp-shape/dataset/3\n",
    "\"\"\"\n",
    "\n",
    "yaml_path = Path(OUTPUT_DIR) / \"data.yaml\"\n",
    "with open(yaml_path, 'w') as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(\"✓ data.yaml created\")\n",
    "print(f\"\\nFiltered dataset ready at: {OUTPUT_DIR}\")\n",
    "print(\"All stamp shapes (circle, oval, rectangle) remapped to class ID 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3209b2c",
   "metadata": {},
   "source": [
    "## Create Updated data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "feef45f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing datasets...\n",
      "\n",
      "TRAIN:\n",
      "  ✓ Kept: 2030 images\n",
      "  ✗ Skipped: 574 images (no valid classes)\n",
      "\n",
      "VALID:\n",
      "  ✓ Kept: 206 images\n",
      "  ✗ Skipped: 44 images (no valid classes)\n",
      "\n",
      "TEST:\n",
      "  ✓ Kept: 98 images\n",
      "  ✗ Skipped: 27 images (no valid classes)\n",
      "\n",
      "==================================================\n",
      "TOTAL: 2334 images kept, 645 images skipped\n"
     ]
    }
   ],
   "source": [
    "def filter_labels_and_copy(split):\n",
    "    \"\"\"\n",
    "    Filter label files to keep only specified classes and remap them to class 1\n",
    "    \"\"\"\n",
    "    source_labels = Path(SOURCE_DIR) / split / \"labels\"\n",
    "    source_images = Path(SOURCE_DIR) / split / \"images\"\n",
    "    output_labels = Path(OUTPUT_DIR) / split / \"labels\"\n",
    "    output_images = Path(OUTPUT_DIR) / split / \"images\"\n",
    "    \n",
    "    if not source_labels.exists():\n",
    "        print(f\"⚠ {split} split not found, skipping...\")\n",
    "        return 0, 0\n",
    "    \n",
    "    label_files = list(source_labels.glob(\"*.txt\"))\n",
    "    kept_count = 0\n",
    "    skipped_count = 0\n",
    "    \n",
    "    for label_file in label_files:\n",
    "        # Read and filter annotations\n",
    "        filtered_lines = []\n",
    "        \n",
    "        with open(label_file, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 5:\n",
    "                    class_id = int(parts[0])\n",
    "                    if class_id in KEEP_CLASSES:\n",
    "                        # Remap to class 1\n",
    "                        parts[0] = str(NEW_CLASS_ID)\n",
    "                        filtered_lines.append(' '.join(parts) + '\\n')\n",
    "        \n",
    "        # Only keep image/label if it has valid annotations\n",
    "        if filtered_lines:\n",
    "            # Write filtered label file\n",
    "            output_label_path = output_labels / label_file.name\n",
    "            with open(output_label_path, 'w') as f:\n",
    "                f.writelines(filtered_lines)\n",
    "            \n",
    "            # Copy corresponding image\n",
    "            img_name = label_file.stem + \".jpg\"\n",
    "            img_path = source_images / img_name\n",
    "            \n",
    "            # Try .png if .jpg doesn't exist\n",
    "            if not img_path.exists():\n",
    "                img_name = label_file.stem + \".png\"\n",
    "                img_path = source_images / img_name\n",
    "            \n",
    "            if img_path.exists():\n",
    "                shutil.copy(img_path, output_images / img_name)\n",
    "                kept_count += 1\n",
    "            else:\n",
    "                print(f\"⚠ Image not found for {label_file.name}\")\n",
    "        else:\n",
    "            skipped_count += 1\n",
    "    \n",
    "    return kept_count, skipped_count\n",
    "\n",
    "\n",
    "# Process all splits\n",
    "print(\"\\nProcessing datasets...\")\n",
    "total_kept = 0\n",
    "total_skipped = 0\n",
    "\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    print(f\"\\n{split.upper()}:\")\n",
    "    kept, skipped = filter_labels_and_copy(split)\n",
    "    print(f\"  ✓ Kept: {kept} images\")\n",
    "    print(f\"  ✗ Skipped: {skipped} images (no valid classes)\")\n",
    "    total_kept += kept\n",
    "    total_skipped += skipped\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"TOTAL: {total_kept} images kept, {total_skipped} images skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c61d303",
   "metadata": {},
   "source": [
    "## Filter Labels and Copy Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7e8f247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Directory structure created\n"
     ]
    }
   ],
   "source": [
    "# Create output directories\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    os.makedirs(f\"{OUTPUT_DIR}/{split}/images\", exist_ok=True)\n",
    "    os.makedirs(f\"{OUTPUT_DIR}/{split}/labels\", exist_ok=True)\n",
    "\n",
    "print(\"✓ Directory structure created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bad0ce0",
   "metadata": {},
   "source": [
    "## Create Output Directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfc35d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: ../datasets/stamp_yolov9\n",
      "Output: ../datasets/stamp_yolov9_filtered\n",
      "Keeping classes: {0, 1, 2}\n",
      "Remapping to class ID: 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Source and destination paths\n",
    "SOURCE_DIR = \"../datasets/stamp_yolov9\"\n",
    "OUTPUT_DIR = \"../datasets/stamp_yolov9_filtered\"\n",
    "\n",
    "# Classes to keep (0, 1, 2) and remap to class 1\n",
    "KEEP_CLASSES = {0, 1, 2}\n",
    "NEW_CLASS_ID = 1  # All stamps become class 1\n",
    "\n",
    "print(f\"Source: {SOURCE_DIR}\")\n",
    "print(f\"Output: {OUTPUT_DIR}\")\n",
    "print(f\"Keeping classes: {KEEP_CLASSES}\")\n",
    "print(f\"Remapping to class ID: {NEW_CLASS_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac44460",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
