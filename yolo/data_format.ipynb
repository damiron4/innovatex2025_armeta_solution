{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7fd078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def visualize_sample(split='train', num_samples=2):\n",
    "    \"\"\"\n",
    "    Visualize random samples with bounding boxes\n",
    "    \"\"\"\n",
    "    images_dir = Path(OUTPUT_DIR) / split / \"images\"\n",
    "    labels_dir = Path(OUTPUT_DIR) / split / \"labels\"\n",
    "    \n",
    "    image_files = list(images_dir.glob(\"*.jpg\"))\n",
    "    \n",
    "    if not image_files:\n",
    "        print(f\"No images found in {split} split\")\n",
    "        return\n",
    "    \n",
    "    samples = random.sample(image_files, min(num_samples, len(image_files)))\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(samples), figsize=(15, 5))\n",
    "    if len(samples) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    class_names = ['signature', 'stamp', 'qr']\n",
    "    colors = ['red', 'blue', 'green']\n",
    "    \n",
    "    for ax, img_path in zip(axes, samples):\n",
    "        # Load image\n",
    "        img = Image.open(img_path)\n",
    "        ax.imshow(img)\n",
    "        \n",
    "        img_width, img_height = img.size\n",
    "        \n",
    "        # Load corresponding label\n",
    "        label_path = labels_dir / (img_path.stem + \".txt\")\n",
    "        \n",
    "        if label_path.exists():\n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) == 5:\n",
    "                        class_id = int(parts[0])\n",
    "                        x_center, y_center, w, h = map(float, parts[1:])\n",
    "                        \n",
    "                        # Convert back to pixel coordinates for visualization\n",
    "                        x = (x_center - w/2) * img_width\n",
    "                        y = (y_center - h/2) * img_height\n",
    "                        w_px = w * img_width\n",
    "                        h_px = h * img_height\n",
    "                        \n",
    "                        # Draw rectangle\n",
    "                        rect = patches.Rectangle(\n",
    "                            (x, y), w_px, h_px,\n",
    "                            linewidth=2,\n",
    "                            edgecolor=colors[class_id],\n",
    "                            facecolor='none'\n",
    "                        )\n",
    "                        ax.add_patch(rect)\n",
    "                        \n",
    "                        # Add label\n",
    "                        ax.text(\n",
    "                            x, y - 5,\n",
    "                            class_names[class_id],\n",
    "                            color=colors[class_id],\n",
    "                            fontsize=10,\n",
    "                            weight='bold',\n",
    "                            bbox=dict(boxstyle='round', facecolor='white', alpha=0.7)\n",
    "                        )\n",
    "        \n",
    "        ax.set_title(img_path.name)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize some samples\n",
    "visualize_sample('train', num_samples=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c3a572",
   "metadata": {},
   "source": [
    "## Verify Conversion (Optional)\n",
    "\n",
    "Check a few samples to ensure the conversion is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64230c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data.yaml file\n",
    "yaml_content = \"\"\"train: ../train/images\n",
    "val: ../valid/images\n",
    "test: ../test/images\n",
    "\n",
    "nc: 3\n",
    "names: ['signature', 'stamp', 'qr']\n",
    "\n",
    "roboflow:\n",
    "  workspace: tech4humans\n",
    "  project: signature-detection\n",
    "  version: 1\n",
    "  license: Unknown\n",
    "  url: https://huggingface.co/datasets/tech4humans/signature-detection\n",
    "\"\"\"\n",
    "\n",
    "yaml_path = Path(OUTPUT_DIR) / \"data.yaml\"\n",
    "with open(yaml_path, 'w') as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(\"✓ data.yaml created\")\n",
    "print(f\"\\nDataset ready at: {OUTPUT_DIR}\")\n",
    "print(\"\\nYou can now use this dataset with YOLOv9!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453e8628",
   "metadata": {},
   "source": [
    "## Create data.yaml Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a5313c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process train split\n",
    "process_split(dataset['train'], 'train', OUTPUT_DIR)\n",
    "\n",
    "# Process validation split (if exists)\n",
    "if 'validation' in dataset:\n",
    "    process_split(dataset['validation'], 'valid', OUTPUT_DIR)\n",
    "else:\n",
    "    # If no validation split, create one from train (10% split)\n",
    "    print(\"\\nNo validation split found, creating from train split (10%)...\")\n",
    "    train_split = dataset['train'].train_test_split(test_size=0.1, seed=42)\n",
    "    process_split(train_split['train'], 'train', OUTPUT_DIR)\n",
    "    process_split(train_split['test'], 'valid', OUTPUT_DIR)\n",
    "\n",
    "# Process test split (if exists)\n",
    "if 'test' in dataset:\n",
    "    process_split(dataset['test'], 'test', OUTPUT_DIR)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"✓ Dataset conversion complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337993d3",
   "metadata": {},
   "source": [
    "## Process All Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef3c7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bbox_to_yolo(bbox, img_width, img_height):\n",
    "    \"\"\"\n",
    "    Convert bbox from [x, y, width, height] to YOLO format\n",
    "    [x_center_norm, y_center_norm, width_norm, height_norm]\n",
    "    \"\"\"\n",
    "    x, y, w, h = bbox\n",
    "    \n",
    "    # Calculate center point\n",
    "    x_center = x + w / 2\n",
    "    y_center = y + h / 2\n",
    "    \n",
    "    # Normalize by image dimensions\n",
    "    x_center_norm = x_center / img_width\n",
    "    y_center_norm = y_center / img_height\n",
    "    w_norm = w / img_width\n",
    "    h_norm = h / img_height\n",
    "    \n",
    "    return x_center_norm, y_center_norm, w_norm, h_norm\n",
    "\n",
    "\n",
    "def process_split(dataset_split, split_name, output_dir):\n",
    "    \"\"\"\n",
    "    Process a dataset split and save in YOLOv9 format\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcessing {split_name} split...\")\n",
    "    \n",
    "    images_dir = Path(output_dir) / split_name / \"images\"\n",
    "    labels_dir = Path(output_dir) / split_name / \"labels\"\n",
    "    \n",
    "    for idx, sample in enumerate(dataset_split):\n",
    "        # Get image\n",
    "        img = sample['image']\n",
    "        \n",
    "        # Handle different image types\n",
    "        if isinstance(img, Image.Image):\n",
    "            pil_img = img\n",
    "        elif isinstance(img, np.ndarray):\n",
    "            pil_img = Image.fromarray(img)\n",
    "        else:\n",
    "            print(f\"Skipping {idx}: Unknown image type {type(img)}\")\n",
    "            continue\n",
    "        \n",
    "        # Convert to RGB if needed\n",
    "        if pil_img.mode != 'RGB':\n",
    "            pil_img = pil_img.convert('RGB')\n",
    "        \n",
    "        img_width, img_height = pil_img.size\n",
    "        \n",
    "        # Generate filename\n",
    "        image_id = sample.get('image_id', idx)\n",
    "        img_filename = f\"img_{image_id:06d}.jpg\"\n",
    "        label_filename = f\"img_{image_id:06d}.txt\"\n",
    "        \n",
    "        # Save image\n",
    "        img_path = images_dir / img_filename\n",
    "        pil_img.save(img_path, 'JPEG')\n",
    "        \n",
    "        # Process annotations\n",
    "        objects = sample.get('objects', {})\n",
    "        bboxes = objects.get('bbox', [])\n",
    "        categories = objects.get('category', [])\n",
    "        \n",
    "        # Write label file\n",
    "        label_path = labels_dir / label_filename\n",
    "        with open(label_path, 'w') as f:\n",
    "            for bbox, category in zip(bboxes, categories):\n",
    "                # Convert bbox to YOLO format\n",
    "                x_center, y_center, w, h = convert_bbox_to_yolo(bbox, img_width, img_height)\n",
    "                \n",
    "                # Ensure values are in valid range [0, 1]\n",
    "                x_center = max(0.0, min(1.0, x_center))\n",
    "                y_center = max(0.0, min(1.0, y_center))\n",
    "                w = max(0.0, min(1.0, w))\n",
    "                h = max(0.0, min(1.0, h))\n",
    "                \n",
    "                # Write in YOLO format: class_id x_center y_center width height\n",
    "                f.write(f\"{category} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\\n\")\n",
    "        \n",
    "        if (idx + 1) % 100 == 0:\n",
    "            print(f\"  Processed {idx + 1} images...\")\n",
    "    \n",
    "    print(f\"✓ {split_name} split complete: {len(dataset_split)} images processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caacc0ae",
   "metadata": {},
   "source": [
    "## Convert to YOLOv9 Format\n",
    "\n",
    "YOLOv9 format: `<class_id> <x_center> <y_center> <width> <height>` (all normalized 0-1)\n",
    "\n",
    "The dataset has bboxes in `[x, y, width, height]` format (absolute pixels), which we'll convert to YOLO format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1f144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading dataset from HuggingFace...\")\n",
    "dataset = load_dataset(\"tech4humans/signature-detection\")\n",
    "\n",
    "print(f\"✓ Dataset loaded\")\n",
    "print(f\"  - Train: {len(dataset['train'])} samples\")\n",
    "if 'validation' in dataset:\n",
    "    print(f\"  - Validation: {len(dataset['validation'])} samples\")\n",
    "if 'test' in dataset:\n",
    "    print(f\"  - Test: {len(dataset['test'])} samples\")\n",
    "\n",
    "# Show sample\n",
    "print(\"\\nSample data structure:\")\n",
    "sample = dataset['train'][0]\n",
    "print(f\"Keys: {sample.keys()}\")\n",
    "if 'objects' in sample:\n",
    "    print(f\"Objects keys: {sample['objects'].keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a3e46b",
   "metadata": {},
   "source": [
    "## Load Dataset from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2104395b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\My_Projects\\innovatex2025_armeta_solution\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Directory structure created\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Output directory structure\n",
    "OUTPUT_DIR = \"../datasets/signature-detection.v1.yolov9\"\n",
    "os.makedirs(f\"{OUTPUT_DIR}/train/images\", exist_ok=True)\n",
    "os.makedirs(f\"{OUTPUT_DIR}/train/labels\", exist_ok=True)\n",
    "os.makedirs(f\"{OUTPUT_DIR}/valid/images\", exist_ok=True)\n",
    "os.makedirs(f\"{OUTPUT_DIR}/valid/labels\", exist_ok=True)\n",
    "os.makedirs(f\"{OUTPUT_DIR}/test/images\", exist_ok=True)\n",
    "os.makedirs(f\"{OUTPUT_DIR}/test/labels\", exist_ok=True)\n",
    "\n",
    "print(\"✓ Directory structure created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d835331d",
   "metadata": {},
   "source": [
    "# Convert HuggingFace Signature Dataset to YOLOv9 Format\n",
    "\n",
    "This notebook converts the `tech4humans/signature-detection` dataset from HuggingFace to YOLOv9 format, similar to the stamp dataset structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf49bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "from PIL import Image\n",
    "\n",
    "OUT_DIR = \"merged_yolo\"\n",
    "TRAIN_SPLIT = 0.9\n",
    "\n",
    "os.makedirs(f\"{OUT_DIR}/images/train\", exist_ok=True)\n",
    "os.makedirs(f\"{OUT_DIR}/images/val\", exist_ok=True)\n",
    "os.makedirs(f\"{OUT_DIR}/labels/train\", exist_ok=True)\n",
    "os.makedirs(f\"{OUT_DIR}/labels/val\", exist_ok=True)\n",
    "\n",
    "# ---------------------------------------\n",
    "# 1) SIGNATURE dataset (JSON → YOLO TXT)\n",
    "# ---------------------------------------\n",
    "\n",
    "SIGN_IMG_DIR = \"signature/img\"\n",
    "SIGN_ANN_DIR = \"signature/ann\"\n",
    "SIGN_CLASS_ID = 0   # signature = class 0\n",
    "\n",
    "def convert_bbox(bbox, w, h):\n",
    "    x, y, bw, bh = bbox\n",
    "    cx = (x + bw/2) / w\n",
    "    cy = (y + bh/2) / h\n",
    "    return cx, cy, bw/w, bh/h\n",
    "\n",
    "for fn in os.listdir(SIGN_ANN_DIR):\n",
    "    if not fn.endswith(\".json\"):\n",
    "        continue\n",
    "\n",
    "    ann_path = os.path.join(SIGN_ANN_DIR, fn)\n",
    "    img_path = os.path.join(SIGN_IMG_DIR, fn.replace(\".json\", \".jpg\"))\n",
    "\n",
    "    if not os.path.exists(img_path):\n",
    "        img_path = img_path.replace(\".jpg\", \".png\")\n",
    "\n",
    "    # choose split\n",
    "    subset = \"train\" if random.random() < TRAIN_SPLIT else \"val\"\n",
    "\n",
    "    # copy image\n",
    "    out_img_path = f\"{OUT_DIR}/images/{subset}/{os.path.basename(img_path)}\"\n",
    "    shutil.copy(img_path, out_img_path)\n",
    "\n",
    "    img = Image.open(img_path)\n",
    "    w, h = img.size\n",
    "\n",
    "    # convert annotation\n",
    "    data = json.load(open(ann_path, \"r\"))\n",
    "    out_label_path = f\"{OUT_DIR}/labels/{subset}/{fn.replace('.json', '.txt')}\"\n",
    "\n",
    "    with open(out_label_path, \"w\") as f:\n",
    "        for bbox in data[\"bbox\"]:\n",
    "            cx, cy, bw, bh = convert_bbox(bbox, w, h)\n",
    "            f.write(f\"{SIGN_CLASS_ID} {cx} {cy} {bw} {bh}\\n\")\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "# 2) STAMP dataset (already YOLO format)\n",
    "# ---------------------------------------\n",
    "\n",
    "STAMP_IMG_DIR = \"stamp/images\"\n",
    "STAMP_LBL_DIR = \"stamp/labels\"\n",
    "STAMP_CLASS_ID = 1   # stamp = class 1\n",
    "\n",
    "print(\"Copying STAMP YOLO dataset...\")\n",
    "\n",
    "for fn in os.listdir(STAMP_IMG_DIR):\n",
    "    if not fn.lower().endswith((\".jpg\", \".png\")):\n",
    "        continue\n",
    "\n",
    "    subset = \"train\" if random.random() < TRAIN_SPLIT else \"val\"\n",
    "\n",
    "    # copy image\n",
    "    shutil.copy(\n",
    "        os.path.join(STAMP_IMG_DIR, fn),\n",
    "        f\"{OUT_DIR}/images/{subset}/{fn}\"\n",
    "    )\n",
    "\n",
    "    # copy label\n",
    "    lbl_path = os.path.join(STAMP_LBL_DIR, fn.replace(\".jpg\", \".txt\").replace(\".png\", \".txt\"))\n",
    "    if os.path.exists(lbl_path):\n",
    "        shutil.copy(\n",
    "            lbl_path,\n",
    "            f\"{OUT_DIR}/labels/{subset}/{os.path.basename(lbl_path)}\"\n",
    "        )\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "# 3) QR dataset\n",
    "# ---------------------------------------\n",
    "\n",
    "# (добавлю как только скажешь, какой формат у qr)\n",
    "# qr_json? qr_yolo? qr_xml?\n",
    "\n",
    "print(\"Dataset merge completed:\", OUT_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
